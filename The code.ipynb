{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fp3xH6M9gA1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
        "\n",
        "class TreePartitionMethod:\n",
        "    def __init__(self, data, num_intervals):\n",
        "        self.data = data\n",
        "        self.num_intervals = num_intervals\n",
        "        self.universe = (min(data), max(data))\n",
        "        self.intervals = self._initial_partition()\n",
        "        self.frequencies = self._calculate_frequencies()\n",
        "        self.avg_frequency = np.mean(self.frequencies)\n",
        "        self.optimized_intervals = self._optimize_intervals()\n",
        "\n",
        "    def _initial_partition(self):\n",
        "        min_val, max_val = self.universe\n",
        "        interval_length = (max_val - min_val) / self.num_intervals\n",
        "        intervals = [(min_val + i * interval_length, min_val + (i + 1) * interval_length) for i in range(self.num_intervals)]\n",
        "        return intervals\n",
        "\n",
        "    def _calculate_frequencies(self):\n",
        "        frequencies = []\n",
        "        for low, high in self.intervals:\n",
        "            count = sum(low <= x < high for x in self.data)\n",
        "            frequencies.append(count)\n",
        "        return frequencies\n",
        "\n",
        "    def _optimize_intervals(self):\n",
        "        optimized_intervals = self.intervals[:]\n",
        "        frequencies = self.frequencies[:]\n",
        "        avg_frequency = self.avg_frequency\n",
        "\n",
        "        while True:\n",
        "            new_intervals = []\n",
        "            new_frequencies = []\n",
        "\n",
        "            for i, (low, high) in enumerate(optimized_intervals):\n",
        "                if frequencies[i] > avg_frequency:\n",
        "                    mid = (low + high) / 2\n",
        "                    new_intervals.append((low, mid))\n",
        "                    new_intervals.append((mid, high))\n",
        "                    new_frequencies.append(sum(low <= x < mid for x in self.data))\n",
        "                    new_frequencies.append(sum(mid <= x < high for x in self.data))\n",
        "                else:\n",
        "                    new_intervals.append((low, high))\n",
        "                    new_frequencies.append(frequencies[i])\n",
        "\n",
        "            if new_intervals == optimized_intervals:\n",
        "                break\n",
        "\n",
        "            optimized_intervals = new_intervals\n",
        "            frequencies = new_frequencies\n",
        "\n",
        "        return optimized_intervals\n",
        "\n",
        "    def get_intervals(self):\n",
        "        return self.optimized_intervals\n",
        "\n",
        "class FuzzyTimeSeriesMarkovChain:\n",
        "    def __init__(self, data, intervals):\n",
        "        self.data = data\n",
        "        self.intervals = intervals\n",
        "        self.fuzzy_sets = self._create_fuzzy_sets()\n",
        "        self.transition_matrix = self._create_transition_matrix()\n",
        "\n",
        "    def _create_fuzzy_sets(self):\n",
        "        fuzzy_sets = []\n",
        "        for value in self.data:\n",
        "            fuzzy_set = [1 if low <= value < high else 0 for low, high in self.intervals]\n",
        "            fuzzy_sets.append(fuzzy_set)\n",
        "        return fuzzy_sets\n",
        "\n",
        "    def _create_transition_matrix(self):\n",
        "        num_intervals = len(self.intervals)\n",
        "        transition_matrix = np.zeros((num_intervals, num_intervals))\n",
        "        for i in range(len(self.fuzzy_sets) - 1):\n",
        "            current_set = self.fuzzy_sets[i]\n",
        "            next_set = self.fuzzy_sets[i + 1]\n",
        "            current_index = current_set.index(1)\n",
        "            next_index = next_set.index(1)\n",
        "            transition_matrix[current_index][next_index] += 1\n",
        "\n",
        "        # Normalize the transition matrix\n",
        "        for i in range(len(transition_matrix)):\n",
        "            total = sum(transition_matrix[i])\n",
        "            if total != 0:\n",
        "                transition_matrix[i] = transition_matrix[i] / total\n",
        "        return transition_matrix\n",
        "\n",
        "    def predict(self, steps):\n",
        "        predictions = []\n",
        "        current_state = self.fuzzy_sets[-1].index(1)\n",
        "        for _ in range(steps):\n",
        "            next_state = np.argmax(self.transition_matrix[current_state])\n",
        "            predictions.append((self.intervals[next_state][0] + self.intervals[next_state][1]) / 2)  # Predict the midpoint of the interval\n",
        "            current_state = next_state\n",
        "        return predictions\n",
        "\n",
        "    def evaluate(self, actual_data):\n",
        "        predictions = self.predict(len(actual_data))\n",
        "        mse = mean_squared_error(actual_data, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mape = mean_absolute_percentage_error(actual_data, predictions)\n",
        "        thiels_u = self._thiels_u(actual_data, predictions)\n",
        "        return mse, rmse, mape, thiels_u\n",
        "\n",
        "    def _thiels_u(self, actual, predicted):\n",
        "        actual = np.array(actual)\n",
        "        predicted = np.array(predicted)\n",
        "        numerator = np.sqrt(np.mean((actual - predicted)**2))\n",
        "        denominator = np.sqrt(np.mean(actual**2)) + np.sqrt(np.mean(predicted**2))\n",
        "        return numerator / denominator\n",
        "\n",
        "# Sample Data\n",
        "data = [112, 115, 120, 130, 140, 150, 160, 170, 180, 190, 200]\n",
        "\n",
        "# Tree Partition Method\n",
        "tpm = TreePartitionMethod(data, num_intervals=5)\n",
        "\n",
        "# Get optimized intervals\n",
        "optimized_intervals = tpm.get_intervals()\n",
        "print(\"Optimized Intervals:\", optimized_intervals)\n",
        "\n",
        "# Fuzzy Time Series Markov Chain Model\n",
        "fts_mc = FuzzyTimeSeriesMarkovChain(data, optimized_intervals)\n",
        "\n",
        "# Predict future values\n",
        "predictions = fts_mc.predict(steps=5)\n",
        "print(\"Predictions:\", predictions)\n",
        "\n",
        "# Evaluate the model (using a hypothetical future dataset)\n",
        "# Replace `actual_future_data` with the actual future data you want to evaluate against.\n",
        "actual_future_data = [210, 220, 230, 240, 250]\n",
        "rmse, mape, thiels_u = fts_mc.evaluate(actual_future_data)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
        "print(\"Thiel's U:\", thiels_u)\n"
      ]
    }
  ]
}